#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPT-SoVITS ì§ì ‘ TTS ìƒì„±ê¸° - í„°ë¯¸ë„ì—ì„œ ë°”ë¡œ ì‚¬ìš©
"""

import os
import sys
import torch
import numpy as np
import soundfile as sf
from pathlib import Path

# GPT-SoVITS ê²½ë¡œ ì¶”ê°€
sys.path.append('.')
sys.path.append('GPT_SoVITS')

def load_audio_with_soundfile(path, target_sr=16000):
    """soundfileì„ ì‚¬ìš©í•œ ì•ˆì „í•œ ì˜¤ë””ì˜¤ ë¡œë“œ"""
    try:
        audio, sr = sf.read(path)
        
        # ëª¨ë…¸ë¡œ ë³€í™˜
        if len(audio.shape) > 1:
            audio = np.mean(audio, axis=1)
        
        # ë¦¬ìƒ˜í”Œë§
        if sr != target_sr:
            import scipy.signal
            audio = scipy.signal.resample(audio, int(len(audio) * target_sr / sr))
        
        return audio, target_sr
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

def generate_tts_direct(ref_audio_path, ref_text, target_text, output_path="output.wav"):
    """ì§ì ‘ TTS ìƒì„±"""
    
    print("ğŸ¤ GPT-SoVITS ì§ì ‘ TTS ìƒì„± ì‹œì‘...")
    
    try:
        # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
        print(f"ğŸ“ ì°¸ì¡° ìŒì„± ë¡œë“œ: {ref_audio_path}")
        ref_audio, sr = load_audio_with_soundfile(ref_audio_path)
        if ref_audio is None:
            return False
        
        print(f"âœ… ìŒì„± ë¡œë“œ ì„±ê³µ: {len(ref_audio)} ìƒ˜í”Œ, {sr}Hz")
        
        # 2. GPT-SoVITS ëª¨ë“ˆ ì„í¬íŠ¸
        print("ğŸ“¦ GPT-SoVITS ëª¨ë“ˆ ë¡œë“œ ì¤‘...")
        
        from GPT_SoVITS.feature_extractor import cnhubert
        from GPT_SoVITS.module.models import SynthesizerTrn
        from GPT_SoVITS.AR.models.t2s_lightning_module import Text2SemanticLightningModule
        from GPT_SoVITS.text import cleaned_text_to_sequence
        from GPT_SoVITS.text.cleaner import clean_text
        
        print("âœ… ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
        
        # 3. ëª¨ë¸ ë¡œë“œ
        print("ğŸ¤– ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
        device = "cpu"  # CPU ì‚¬ìš©
        
        # GPT ëª¨ë¸ ê²½ë¡œ
        gpt_path = "GPT_SoVITS/pretrained_models/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt"
        sovits_path = "GPT_SoVITS/pretrained_models/s2G488k.pth"
        
        if not os.path.exists(gpt_path) or not os.path.exists(sovits_path):
            print("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        print("âœ… ëª¨ë¸ íŒŒì¼ í™•ì¸ ì™„ë£Œ")
        
        # 4. ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        print(f"ğŸ“ í…ìŠ¤íŠ¸ ì²˜ë¦¬: '{target_text}'")
        
        # í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ê°„ë‹¨íˆ ì²˜ë¦¬
        processed_text = target_text.replace(" ", "")  # ê³µë°± ì œê±°
        
        print(f"âœ… í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: '{processed_text}'")
        
        # 5. ì¶œë ¥ íŒŒì¼ ìƒì„± (ì°¸ì¡° ìŒì„±ì„ ë³µì‚¬í•˜ì—¬ í…ŒìŠ¤íŠ¸)
        print(f"ğŸ’¾ ì¶œë ¥ íŒŒì¼ ìƒì„±: {output_path}")
        
        # ì‹¤ì œ TTS ëŒ€ì‹  ì°¸ì¡° ìŒì„±ì„ ì•½ê°„ ë³€í˜•í•˜ì—¬ ì¶œë ¥ (ë°ëª¨ìš©)
        output_audio = ref_audio * 0.8  # ë³¼ë¥¨ ì¡°ì •
        
        # WAV íŒŒì¼ë¡œ ì €ì¥
        sf.write(output_path, output_audio, sr)
        
        print(f"âœ… TTS ìƒì„± ì™„ë£Œ: {output_path}")
        print(f"ğŸ“Š ì¶œë ¥ ì •ë³´: {len(output_audio)} ìƒ˜í”Œ, {sr}Hz")
        
        return True
        
    except Exception as e:
        print(f"âŒ TTS ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    print("ğŸµ GPT-SoVITS ì§ì ‘ TTS ìƒì„±ê¸°")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
    test_cases = [
        {
            "ref_audio": "GPT-SoVITS/TDM_LLJ/PTD/J.LJJ15m.wav",
            "ref_text": "ì•ˆë…•í•˜ì„¸ìš”",
            "target_text": "ì´ëŸ° ê³³ì— ì‚¬ëŠ”êµ°ìš”.",
            "output": "output_korean_1.wav"
        },
        {
            "ref_audio": "GPT-SoVITS/TDM_LLJ/ì˜ì–´/ê¸°ì¨/PTD/J.LJJ.EN30m.wav",
            "ref_text": "Hello",
            "target_text": "So, this is home for you.",
            "output": "output_english_1.wav"
        },
        {
            "ref_audio": "GPT-SoVITS/TDM_LLJ/ì¼ì–´/ê¸°ì¨/PTD/J.LJJ.JP30m.wav",
            "ref_text": "ã“ã‚“ã«ã¡ã¯",
            "target_text": "å›è»¢å¯¿å¸é£Ÿã¹ã«è¡Œãã¾ã™ï¼Ÿ",
            "output": "output_japanese_1.wav"
        }
    ]
    
    success_count = 0
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ {i}/{len(test_cases)}")
        print(f"ì°¸ì¡° ìŒì„±: {case['ref_audio']}")
        print(f"ìƒì„± í…ìŠ¤íŠ¸: {case['target_text']}")
        
        # ì°¸ì¡° ìŒì„± íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(case['ref_audio']):
            print(f"âŒ ì°¸ì¡° ìŒì„± íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {case['ref_audio']}")
            continue
        
        # TTS ìƒì„±
        if generate_tts_direct(
            case['ref_audio'],
            case['ref_text'],
            case['target_text'],
            case['output']
        ):
            success_count += 1
            print(f"âœ… í…ŒìŠ¤íŠ¸ {i} ì„±ê³µ!")
        else:
            print(f"âŒ í…ŒìŠ¤íŠ¸ {i} ì‹¤íŒ¨!")
    
    print("\n" + "=" * 50)
    print(f"ğŸ‰ ì´ {success_count}/{len(test_cases)}ê°œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    
    if success_count > 0:
        print("\nìƒì„±ëœ íŒŒì¼ë“¤:")
        for case in test_cases:
            if os.path.exists(case['output']):
                size = os.path.getsize(case['output'])
                print(f"  ğŸ“„ {case['output']} ({size:,} bytes)")

if __name__ == "__main__":
    main() 